{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/OJO/LUIS/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_atis():\n",
    "\n",
    "    f = gzip.open(path+'atis.fold0.pkl.gz','rb')\n",
    "    train, valid, test, dicts = pickle.load(f)\n",
    "    \n",
    "    w2i = dicts['words2idx']\n",
    "    l2i = dicts['labels2idx']\n",
    "    i2w = {i:w for w,i in dicts['words2idx'].iteritems()}\n",
    "    i2l = {i:l for l,i in dicts['labels2idx'].iteritems()}  \n",
    "\n",
    "    X_train = [map(i2w.get, encoded_sent) for encoded_sent in train[0]]\n",
    "    X_valid = [map(i2w.get, encoded_sent) for encoded_sent in valid[0]]\n",
    "    X_test = [map(i2w.get, encoded_sent) for encoded_sent in test[0]]\n",
    "    Y_train = [map(i2l.get, encoded_labels) for encoded_labels in train[2]]\n",
    "    Y_valid = [map(i2l.get, encoded_labels) for encoded_labels in valid[2]]\n",
    "    Y_test = [map(i2l.get, encoded_sent) for encoded_sent in test[2]]\n",
    "\n",
    "    X_train = X_train + X_valid\n",
    "    Y_train = Y_train + Y_valid\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test, {'i2w':i2w,'w2i':w2i,'i2l':i2l,'l2i':l2i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.7 s, sys: 47 ms, total: 1.74 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, Y_train, X_test, Y_test, dicts = load_atis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_set = list(dicts['l2i'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization (CRF & MaxEnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def crf_word_window(w_idx, X): # X: X_train[0]\n",
    "    features = ['0'+X[w_idx]]\n",
    "    if w_idx > 0:\n",
    "        features.append('-1'+X[w_idx-1])\n",
    "        if w_idx > 1:\n",
    "            features.append('-2'+X[w_idx-2])\n",
    "        else: features.append('BOS')\n",
    "    else: features += ['BOS','BOS']\n",
    "    if w_idx < len(X)-1:\n",
    "        features.append('+1'+X[w_idx+1])\n",
    "        if w_idx < len(X)-2:\n",
    "            features.append('+2'+X[w_idx+2])\n",
    "        else: features.append('EOS')\n",
    "    else: features += ['EOS','EOS']\n",
    "    return features\n",
    "\n",
    "def maxent_word_window(w_idx, X): # X: X_train[0]\n",
    "    features = {'0word':X[w_idx]}\n",
    "    if w_idx > 0:\n",
    "        features['-1word'] = X[w_idx-1]\n",
    "        if w_idx > 1:\n",
    "            features['-2word'] = X[w_idx-2]\n",
    "        else: features['-2word'] = 'BOS'\n",
    "    else: \n",
    "        features['-2word'] = features['-1word'] = 'BOS'\n",
    "    if w_idx < len(X)-1:\n",
    "        features['+1word'] = X[w_idx+1]\n",
    "        if w_idx < len(X)-2:\n",
    "            features['+2word'] = X[w_idx+2]\n",
    "        else: features['+2word'] = 'EOS'\n",
    "    else: features['+2word'] = features['+1word'] = 'EOS'\n",
    "    return features\n",
    "\n",
    "def sent_window(X, word_window):\n",
    "    return [word_window(w_idx, X) for w_idx in xrange(len(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0what', 'BOS', 'BOS', '+1flights', '+2leave'],\n",
       " ['0flights', '-1what', 'BOS', '+1leave', '+2atlanta'],\n",
       " ['0leave', '-1flights', '-2what', '+1atlanta', '+2at'],\n",
       " ['0atlanta', '-1leave', '-2flights', '+1at', '+2about'],\n",
       " ['0at', '-1atlanta', '-2leave', '+1about', '+2DIGIT'],\n",
       " ['0about', '-1at', '-2atlanta', '+1DIGIT', '+2in'],\n",
       " ['0DIGIT', '-1about', '-2at', '+1in', '+2the'],\n",
       " ['0in', '-1DIGIT', '-2about', '+1the', '+2afternoon'],\n",
       " ['0the', '-1in', '-2DIGIT', '+1afternoon', '+2and'],\n",
       " ['0afternoon', '-1the', '-2in', '+1and', '+2arrive'],\n",
       " ['0and', '-1afternoon', '-2the', '+1arrive', '+2in'],\n",
       " ['0arrive', '-1and', '-2afternoon', '+1in', '+2san'],\n",
       " ['0in', '-1arrive', '-2and', '+1san', '+2francisco'],\n",
       " ['0san', '-1in', '-2arrive', '+1francisco', 'EOS'],\n",
       " ['0francisco', '-1san', '-2in', 'EOS', 'EOS']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_window(sample,word_window=crf_word_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'+1word': 'flights',\n",
       "  '+2word': 'leave',\n",
       "  '-1word': 'BOS',\n",
       "  '-2word': 'BOS',\n",
       "  '0word': 'what'},\n",
       " {'+1word': 'leave',\n",
       "  '+2word': 'atlanta',\n",
       "  '-1word': 'what',\n",
       "  '-2word': 'BOS',\n",
       "  '0word': 'flights'},\n",
       " {'+1word': 'atlanta',\n",
       "  '+2word': 'at',\n",
       "  '-1word': 'flights',\n",
       "  '-2word': 'what',\n",
       "  '0word': 'leave'},\n",
       " {'+1word': 'at',\n",
       "  '+2word': 'about',\n",
       "  '-1word': 'leave',\n",
       "  '-2word': 'flights',\n",
       "  '0word': 'atlanta'},\n",
       " {'+1word': 'about',\n",
       "  '+2word': 'DIGIT',\n",
       "  '-1word': 'atlanta',\n",
       "  '-2word': 'leave',\n",
       "  '0word': 'at'},\n",
       " {'+1word': 'DIGIT',\n",
       "  '+2word': 'in',\n",
       "  '-1word': 'at',\n",
       "  '-2word': 'atlanta',\n",
       "  '0word': 'about'},\n",
       " {'+1word': 'in',\n",
       "  '+2word': 'the',\n",
       "  '-1word': 'about',\n",
       "  '-2word': 'at',\n",
       "  '0word': 'DIGIT'},\n",
       " {'+1word': 'the',\n",
       "  '+2word': 'afternoon',\n",
       "  '-1word': 'DIGIT',\n",
       "  '-2word': 'about',\n",
       "  '0word': 'in'},\n",
       " {'+1word': 'afternoon',\n",
       "  '+2word': 'and',\n",
       "  '-1word': 'in',\n",
       "  '-2word': 'DIGIT',\n",
       "  '0word': 'the'},\n",
       " {'+1word': 'and',\n",
       "  '+2word': 'arrive',\n",
       "  '-1word': 'the',\n",
       "  '-2word': 'in',\n",
       "  '0word': 'afternoon'},\n",
       " {'+1word': 'arrive',\n",
       "  '+2word': 'in',\n",
       "  '-1word': 'afternoon',\n",
       "  '-2word': 'the',\n",
       "  '0word': 'and'},\n",
       " {'+1word': 'in',\n",
       "  '+2word': 'san',\n",
       "  '-1word': 'and',\n",
       "  '-2word': 'afternoon',\n",
       "  '0word': 'arrive'},\n",
       " {'+1word': 'san',\n",
       "  '+2word': 'francisco',\n",
       "  '-1word': 'arrive',\n",
       "  '-2word': 'and',\n",
       "  '0word': 'in'},\n",
       " {'+1word': 'francisco',\n",
       "  '+2word': 'EOS',\n",
       "  '-1word': 'in',\n",
       "  '-2word': 'arrive',\n",
       "  '0word': 'san'},\n",
       " {'+1word': 'EOS',\n",
       "  '+2word': 'EOS',\n",
       "  '-1word': 'san',\n",
       "  '-2word': 'in',\n",
       "  '0word': 'francisco'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_window(sample,word_window=maxent_word_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import os, cPickle, time, random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CRF:\n",
    "    \n",
    "    def __init__(self, X_train, Y_train, X_test, Y_test, \n",
    "                 config={'c1': 1.0,'c2': 1e-3,\n",
    "                         'max_iterations': 50,\n",
    "                         'feature.possible_transitions':True}):\n",
    "        self.X_train, self.Y_train = X_train, Y_train\n",
    "        self.X_test, self.Y_test = X_test, Y_test\n",
    "        self.config = config\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        crf_ner = pycrfsuite.Trainer(verbose=0)\n",
    "        crf_ner.set_params(self.config)\n",
    "        X_train_featurized = [sent_window(X,word_window=crf_word_window) \n",
    "                              for X in X_train]\n",
    "        for X,Y in zip(X_train_featurized, self.Y_train):\n",
    "            crf_ner.append(X,Y)\n",
    "        crf_ner.train('words_window.crfsuite')\n",
    "        self.tagger = pycrfsuite.Tagger()\n",
    "        self.tagger.open('words_window.crfsuite')\n",
    "        \n",
    "    def get_confusion_by_cv(self, k=5):\n",
    "        \n",
    "        def cv_partition(X, Y, k=k):\n",
    "            k = max(1,k)\n",
    "            step = int(len(X)/k)\n",
    "            chunked = []\n",
    "            for i in xrange(0, len(X), step):\n",
    "                if i+2*step<len(X):\n",
    "                    chunked.append((X[i:i+step],Y[i:i+step]))\n",
    "                else:\n",
    "                    chunked.append((X[i:],Y[i:]))\n",
    "            return chunked  \n",
    "        \n",
    "        train_chunks = cv_partition(self.X_train,self.Y_train)\n",
    "        \n",
    "        cms = {}\n",
    "        \n",
    "        for i in xrange(k):\n",
    "            print \"... cross validation %dth round\" % (i+1)\n",
    "            x_valid, y_valid = train_chunks[i]\n",
    "            x_train, y_train = [], []\n",
    "            for x,y in train_chunks[:i]+train_chunks[i+1:]:\n",
    "                x_train += x\n",
    "                y_train += y\n",
    "            crf = pycrfsuite.Trainer(verbose=0)\n",
    "            crf.set_params(self.config)\n",
    "            x_train_featurized = [sent_window(x,word_window=crf_word_window)\n",
    "                                  for x in x_train]\n",
    "            for x,y in zip(x_train_featurized, y_train):\n",
    "                crf.append(x,y)\n",
    "            crf.train('cv_crf.crfsuite')\n",
    "            tagger = pycrfsuite.Tagger()\n",
    "            tagger.open('cv_crf.crfsuite')\n",
    "            x_valid_featurized = [sent_window(x,word_window=crf_word_window)\n",
    "                                 for x in x_valid]\n",
    "            y_pred = [tagger.tag(sent) for sent in x_valid_featurized]\n",
    "            y_true = y_valid\n",
    "            y_true_merged = list(chain.from_iterable(y_true))\n",
    "            y_pred_merged = list(chain.from_iterable(y_pred))  \n",
    "            labels = list(set(y_true_merged))\n",
    "            label2cmidx = {l:i for i,l in enumerate(labels)}\n",
    "            cms[i] = {'cm':confusion_matrix(y_true_merged,y_pred_merged,labels),\n",
    "                      'l2i':label2cmidx, 'i2l':labels}\n",
    "        \n",
    "        return cms     \n",
    "        \n",
    "    def tag(self):\n",
    "        \n",
    "        X_test_featurized = [sent_window(X,word_window=crf_word_window) \n",
    "                             for X in X_test]\n",
    "        y_pred = [self.tagger.tag(sent) for sent in X_test_featurized]\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \n",
    "        y_true = self.Y_test\n",
    "        y_pred = self.tag()\n",
    "        y_true_merged = list(chain.from_iterable(y_true))\n",
    "        y_pred_merged = list(chain.from_iterable(y_pred))\n",
    "        \n",
    "        print \"Accuracy: %.6f%%\" % (accuracy_score(y_true_merged,y_pred_merged)*100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = CRF(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.216569%\n"
     ]
    }
   ],
   "source": [
    "crf.evaluate() # result from running .train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cross validation 1th round\n",
      "... cross validation 2th round\n",
      "... cross validation 3th round\n",
      "... cross validation 4th round\n",
      "... cross validation 5th round\n",
      "CPU times: user 7min 54s, sys: 1.74 s, total: 7min 56s\n",
      "Wall time: 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cms = crf.get_confusion_by_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GET THE LIST CONFUSED LABEL-TYPE (EXPERIMENTING RADICAL SET NOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "div = lambda x,y: 0 if y==0 else x/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_confusion(cm, l2i, i2l):\n",
    "    \n",
    "    confused = defaultdict(list)\n",
    "    for l in l2i.iterkeys():\n",
    "        l_vec = cm[:,l2i[l]]\n",
    "        if div(l_vec[l2i[l]],l_vec.sum())<.5:\n",
    "            label_list = [i2l[i] for i,l_i in enumerate(l_vec) if l_i!=0]\n",
    "            if len(label_list) > 0:\n",
    "                confused[l] = label_list\n",
    "    \n",
    "    return confused\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.21 ms, sys: 1.68 ms, total: 5.89 ms\n",
      "Wall time: 4.62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cms_confused = []\n",
    "for i in cms.iterkeys():\n",
    "    cms_confused.append(get_confusion(cms[i]['cm'],cms[i]['l2i'],cms[i]['i2l']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'list'>, {'I-toloc.airport_name': ['I-airport_name', 'O', 'I-toloc.airport_name', 'I-fromloc.airport_name'], 'B-arrive_time.period_of_day': ['B-depart_time.period_of_day'], 'B-toloc.airport_name': ['B-fromloc.airport_name', 'B-airport_name', 'B-toloc.airport_name']})\n",
      "\n",
      "defaultdict(<type 'list'>, {'I-toloc.airport_name': ['I-airport_name', 'I-fromloc.airport_name', 'I-toloc.airport_name'], 'B-arrive_time.period_of_day': ['B-depart_time.period_of_day', 'B-arrive_time.time'], 'I-flight_mod': ['B-fromloc.city_name']})\n",
      "\n",
      "defaultdict(<type 'list'>, {})\n",
      "\n",
      "defaultdict(<type 'list'>, {'B-arrive_time.period_of_day': ['B-arrive_time.period_of_day', 'B-depart_time.period_of_day'], 'I-flight_mod': ['B-arrive_time.time', 'O']})\n",
      "\n",
      "defaultdict(<type 'list'>, {'I-city_name': ['I-toloc.city_name', 'B-city_name', 'I-city_name', 'O', 'B-toloc.city_name'], 'I-flight_mod': ['B-flight_time', 'O', 'I-flight_time']})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for confused in cms_confused:\n",
    "    print confused\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def conservative_set(cms_confused): # takes the intersection of all confused label types.\n",
    "    \n",
    "#     all_confused = defaultdict(list)\n",
    "#     keys = list({key for confused in cms_confused for key in confused.keys()})\n",
    "#     for key in keys:\n",
    "#         for confused in cms_confused:\n",
    "#             if key in confused.keys():\n",
    "\n",
    "# this doesn't make much sense actually, because we'd often get {} as the intersection with high-performance models.\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def radical_set(cms_confused): # takes the union of all confused label types.\n",
    "    \n",
    "    all_confused = defaultdict(list)\n",
    "    for confused in cms_confused:\n",
    "        for label in confused.iterkeys():\n",
    "            if label in all_confused.keys():\n",
    "                all_confused[label] += confused[label]\n",
    "            else:\n",
    "                all_confused[label] = confused[label]\n",
    "    \n",
    "    for label in all_confused.iterkeys():\n",
    "        all_confused[label] = list(set(all_confused[label]))\n",
    "    \n",
    "    return all_confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "radical_confused = radical_set(cms_confused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'B-arrive_time.period_of_day': ['B-depart_time.period_of_day',\n",
       "              'B-arrive_time.time',\n",
       "              'B-arrive_time.period_of_day'],\n",
       "             'B-toloc.airport_name': ['B-airport_name',\n",
       "              'B-fromloc.airport_name',\n",
       "              'B-toloc.airport_name'],\n",
       "             'I-city_name': ['B-toloc.city_name',\n",
       "              'B-city_name',\n",
       "              'I-toloc.city_name',\n",
       "              'I-city_name',\n",
       "              'O'],\n",
       "             'I-flight_mod': ['B-arrive_time.time',\n",
       "              'I-flight_time',\n",
       "              'B-flight_time',\n",
       "              'O',\n",
       "              'B-fromloc.city_name'],\n",
       "             'I-toloc.airport_name': ['I-toloc.airport_name',\n",
       "              'I-airport_name',\n",
       "              'O',\n",
       "              'I-fromloc.airport_name']})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radical_confused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAIN MODEL TO GET PRED(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 461 ms, total: 2min 7s\n",
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_featurized_crf = [sent_window(X,word_window=crf_word_window)\n",
    "                     for X in crf.X_test]\n",
    "X_test_featurized_maxent = [] # a list of featurized x's\n",
    "for X in crf.X_test:\n",
    "    X_test_featurized_maxent += sent_window(X,word_window=maxent_word_window)\n",
    "y_pred = [crf.tagger.tag(sent) for sent in X_test_featurized_crf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = crf.Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_merged = list(chain.from_iterable(y_true)) # word/sent order preserved\n",
    "y_pred_merged = list(chain.from_iterable(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.216569%\n"
     ]
    }
   ],
   "source": [
    "# BEFORE RETAGGING\n",
    "print \"Accuracy: %.6f%%\" % (accuracy_score(y_true_merged,y_pred_merged)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def retag_check(X,Y): # X: featurized X_test for maxent; Y: y_pred_merged from crf\n",
    "    \n",
    "    for i,y in enumerate(Y):\n",
    "        if y in radical_confused.keys():\n",
    "            max_label = ('',0)\n",
    "            maxent_probdist = maxent.tagger.prob_classify(X[i])\n",
    "            for label in radical_confused[y]:\n",
    "                p_label = maxent_probdist.prob(label)\n",
    "                if p_label >= max_label[1]:\n",
    "                    max_label = (label,p_label)\n",
    "            print 'old tag: ', Y[i], '; new tag: ', max_label[0], '(',max_label[1],')', '; true tag: ', y_true_merged[i]\n",
    "            Y[i] = max_label[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old tag:  I-city_name ; new tag:  I-city_name ( 0.727243481069 ) ; true tag:  I-city_name\n",
      "old tag:  B-toloc.airport_name ; new tag:  B-toloc.airport_name ( 0.80861774295 ) ; true tag:  B-toloc.airport_name\n",
      "old tag:  I-toloc.airport_name ; new tag:  I-toloc.airport_name ( 0.625527480815 ) ; true tag:  I-toloc.airport_name\n",
      "old tag:  I-city_name ; new tag:  I-city_name ( 0.235407372141 ) ; true tag:  I-airport_name\n",
      "old tag:  I-city_name ; new tag:  I-city_name ( 0.21746858435 ) ; true tag:  I-airport_name\n",
      "old tag:  I-city_name ; new tag:  I-toloc.city_name ( 0.566995195562 ) ; true tag:  I-city_name\n",
      "old tag:  I-city_name ; new tag:  I-city_name ( 0.161607521087 ) ; true tag:  B-period_of_day\n",
      "old tag:  I-city_name ; new tag:  O ( 0.0848734115861 ) ; true tag:  B-period_of_day\n",
      "old tag:  I-city_name ; new tag:  I-toloc.city_name ( 0.150202467149 ) ; true tag:  I-city_name\n",
      "old tag:  B-toloc.airport_name ; new tag:  B-toloc.airport_name ( 0.0913130872196 ) ; true tag:  B-depart_time.time\n",
      "old tag:  I-toloc.airport_name ; new tag:  I-toloc.airport_name ( 0.0279885965542 ) ; true tag:  I-depart_time.time\n",
      "old tag:  I-city_name ; new tag:  O ( 0.203422574737 ) ; true tag:  I-state_name\n",
      "old tag:  I-city_name ; new tag:  I-city_name ( 0.592021500463 ) ; true tag:  I-city_name\n",
      "old tag:  I-city_name ; new tag:  I-toloc.city_name ( 0.396451977538 ) ; true tag:  I-city_name\n",
      "old tag:  I-city_name ; new tag:  I-city_name ( 0.396533813193 ) ; true tag:  I-city_name\n",
      "old tag:  I-city_name ; new tag:  I-city_name ( 0.533753376377 ) ; true tag:  I-city_name\n",
      "old tag:  I-city_name ; new tag:  I-city_name ( 0.533753376377 ) ; true tag:  I-city_name\n",
      "old tag:  B-toloc.airport_name ; new tag:  B-toloc.airport_name ( 0.178900487648 ) ; true tag:  B-toloc.airport_name\n",
      "old tag:  I-toloc.airport_name ; new tag:  O ( 0.415596857975 ) ; true tag:  I-toloc.airport_name\n",
      "old tag:  B-toloc.airport_name ; new tag:  B-toloc.airport_name ( 0.16037190682 ) ; true tag:  B-toloc.airport_name\n",
      "old tag:  I-toloc.airport_name ; new tag:  O ( 0.415596857975 ) ; true tag:  I-toloc.airport_name\n",
      "old tag:  I-city_name ; new tag:  O ( 0.176686299272 ) ; true tag:  I-city_name\n"
     ]
    }
   ],
   "source": [
    "retag_check(X_test_featurized_maxent,y_pred_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.151337%\n"
     ]
    }
   ],
   "source": [
    "# AFTER RETAGGING\n",
    "print \"Accuracy: %.6f%%\" % (accuracy_score(y_true_merged,y_pred_merged)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaxEnt Retagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from nltk import MaxentClassifier, classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MaxEnt:\n",
    "    \n",
    "    def __init__(self,X_train, Y_train, X_test, Y_test):\n",
    "        self.X_train, self.Y_train = X_train, Y_train\n",
    "        self.X_test, self.Y_test = X_test, Y_test\n",
    "        self.train()\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        X_train_featurized = [sent_window(X,word_window=maxent_word_window) \n",
    "                              for X in self.X_train]\n",
    "        train_featurized = [(w_fts,label) \n",
    "                            for X,Y in zip(X_train_featurized,self.Y_train)\n",
    "                            for w_fts,label in zip(X,Y)]\n",
    "        self.tagger = MaxentClassifier.train(train_featurized, \n",
    "                                             algorithm='megam', \n",
    "                                             trace=3, max_iter=10)\n",
    "    \n",
    "    def tag(self):\n",
    "        return\n",
    "    \n",
    "    def evaluate(self):\n",
    "        X_test_featurized = [sent_window(X,word_window=maxent_word_window) \n",
    "                              for X in self.X_test]\n",
    "        test_featurized = [(w_fts,label) \n",
    "                           for X,Y in zip(X_test_featurized,self.Y_test) \n",
    "                           for w_fts,label in zip(X,Y)]\n",
    "        print \"Accuracy: %.6f%%\" % (classify.accuracy(self.tagger,test_featurized)*100)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.7 s, sys: 373 ms, total: 30 s\n",
      "Wall time: 9min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "maxent = MaxEnt(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.596869%\n"
     ]
    }
   ],
   "source": [
    "maxent.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
