{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATIS in LUIS\n",
    "\n",
    "* **Task I:** ATIS raw data => LUIS-json app format (importable to LUIS).\n",
    "* **Task II:** \n",
    "    * a. Validation: using luis.Luis(..).analyze to predict on valid/test set (i.e. y_hat), then compare that with the actual labeled data in atis pickle (i.e. y_true).\n",
    "    * b. Evaluation: Jaccard and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Labeled Data $\\Rightarrow$ LUIS JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, gzip, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/jacobsw/Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "with open('ojoatis.json') as json_file:\n",
    "    ojoatis = json.load(json_file)\n",
    "joshentities = ojoatis['entities']\n",
    "''' FORMAT:\n",
    "[{u'children': [u'arrive_time.end_time',\n",
    "   u'arrive_time.period_mod',\n",
    "   u'arrive_time.period_of_day',\n",
    "   u'arrive_time.start_time',\n",
    "   u'arrive_time.time_relative'],\n",
    "  u'name': u'arrive_time'},\n",
    " {u'children': [u'depart_time.end_time',\n",
    "   u'depart_time.period_mod',\n",
    "   u'depart_time.period_of_day',\n",
    "   u'depart_time.start_time',\n",
    "   u'depart_time.time',\n",
    "   u'depart_time.time_relative',\n",
    "   u'meal',\n",
    "   u'meal_description'],\n",
    "  u'name': u'depart_time_meal'},\n",
    "  ...\n",
    "'''\n",
    "print 'DONE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ojoatis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "def entities_dict_transform(entities):\n",
    "    new_dict = {}\n",
    "    for entry in entities:\n",
    "        for child in entry['children']:\n",
    "            new_dict[child] = entry['name']\n",
    "    return new_dict\n",
    "''' TRANSFORMED:\n",
    "{u'aircraft_code': u'codes_types',\n",
    " u'airline_code': u'codes_types',\n",
    " u'airline_name': u'from_loc',\n",
    " u'airport_code': u'codes_types',\n",
    " u'airport_name': u'from_loc',\n",
    " u'arrive_date.date_relative': u'arrive_date',\n",
    " u'arrive_date.day_name': u'arrive_date',\n",
    " u'arrive_date.day_number': u'arrive_date',\n",
    " ...\n",
    "'''\n",
    "print 'DONE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'children': [u'arrive_time.end_time',\n",
       "   u'arrive_time.period_mod',\n",
       "   u'arrive_time.period_of_day',\n",
       "   u'arrive_time.start_time',\n",
       "   u'arrive_time.time_relative',\n",
       "   u'arrive_time.time'],\n",
       "  u'name': u'arrive_time'},\n",
       " {u'children': [u'depart_time.end_time',\n",
       "   u'depart_time.period_mod',\n",
       "   u'depart_time.period_of_day',\n",
       "   u'depart_time.start_time',\n",
       "   u'depart_time.time',\n",
       "   u'depart_time.time_relative',\n",
       "   u'meal',\n",
       "   u'meal_description'],\n",
       "  u'name': u'depart_time_meal'},\n",
       " {u'children': [u'return_date.date_relative',\n",
       "   u'return_date.day_name',\n",
       "   u'return_date.day_number',\n",
       "   u'return_date.month_name',\n",
       "   u'return_date.today_relative',\n",
       "   u'return_time.period_mod',\n",
       "   u'return_time.period_of_day',\n",
       "   u'cost_relative',\n",
       "   u'fare_amount'],\n",
       "  u'name': u'return_cost'},\n",
       " {u'children': [u'flight',\n",
       "   u'flight_days',\n",
       "   u'flight_mod',\n",
       "   u'flight_number',\n",
       "   u'flight_stop',\n",
       "   u'flight_time',\n",
       "   u'round_trip',\n",
       "   u'compartment',\n",
       "   u'economy',\n",
       "   u'connect'],\n",
       "  u'name': u'flight'},\n",
       " {u'children': [u'fromloc.airport_code',\n",
       "   u'fromloc.airport_name',\n",
       "   u'fromloc.city_name',\n",
       "   u'fromloc.state_code',\n",
       "   u'fromloc.state_name',\n",
       "   u'airline_name',\n",
       "   u'airport_name',\n",
       "   u'city_name',\n",
       "   u'state_name'],\n",
       "  u'name': u'from_loc'},\n",
       " {u'children': [u'aircraft_code',\n",
       "   u'airline_code',\n",
       "   u'airport_code',\n",
       "   u'booking_class',\n",
       "   u'fare_basis_code',\n",
       "   u'meal_code',\n",
       "   u'restriction_code',\n",
       "   u'state_code',\n",
       "   u'transport_type',\n",
       "   u'class_type'],\n",
       "  u'name': u'codes_types'},\n",
       " {u'children': [u'day_name',\n",
       "   u'day_number',\n",
       "   u'days_code',\n",
       "   u'month_name',\n",
       "   u'period_of_day',\n",
       "   u'time',\n",
       "   u'time_relative',\n",
       "   u'today_relative'],\n",
       "  u'name': u'misc_date_time'},\n",
       " {u'children': [u'depart_date.date_relative',\n",
       "   u'depart_date.day_name',\n",
       "   u'depart_date.day_number',\n",
       "   u'depart_date.month_name',\n",
       "   u'depart_date.today_relative',\n",
       "   u'depart_date.year',\n",
       "   u'mod',\n",
       "   u'or'],\n",
       "  u'name': u'depart_date_mod_or'},\n",
       " {u'children': [u'stoploc.airport_code',\n",
       "   u'stoploc.airport_name',\n",
       "   u'stoploc.city_name',\n",
       "   u'stoploc.state_code',\n",
       "   u'toloc.airport_code',\n",
       "   u'toloc.airport_name',\n",
       "   u'toloc.city_name',\n",
       "   u'toloc.country_name',\n",
       "   u'toloc.state_code',\n",
       "   u'toloc.state_name'],\n",
       "  u'name': u'stop_to_loc'},\n",
       " {u'children': [u'arrive_date.date_relative',\n",
       "   u'arrive_date.day_name',\n",
       "   u'arrive_date.day_number',\n",
       "   u'arrive_date.month_name',\n",
       "   u'arrive_date.today_relative'],\n",
       "  u'name': u'arrive_date'}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joshentities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joshentities = entities_dict_transform(joshentities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ATIS:\n",
    "    # takes an atis pickle, and extract utterances in luis-json format.\n",
    "    \n",
    "    def __init__(self, filename='/Users/jacobsw/Downloads/atis.fold1.pkl.gz',\n",
    "                       entities=joshentities):\n",
    "        self.filename = filename\n",
    "        self.entities = entities\n",
    "        self.__load()\n",
    "    \n",
    "    def __load(self):\n",
    "        f = gzip.open(self.filename, 'rb')\n",
    "        self.train_set, self.valid_set, self.test_set, self.dicts = pickle.load(f)\n",
    "        f.close()\n",
    "        self.idx2labels = {idx:label for (label,idx) in self.dicts['labels2idx'].iteritems()}\n",
    "        self.idx2words = {idx:word for (word,idx) in self.dicts['words2idx'].iteritems()}\n",
    "    \n",
    "    def get_annotated_sent(self, sent_idx, source='train'):\n",
    "        assert source in ['train','valid','test']\n",
    "        if source=='train': src = self.train_set\n",
    "        elif source=='valid': src = self.valid_set\n",
    "        else: src = self.test_set\n",
    "        annotated = zip(map(self.idx2words.get,src[0][sent_idx]),\n",
    "                        map(self.idx2labels.get,src[2][sent_idx]))\n",
    "        return annotated\n",
    "    \n",
    "    def get_utterance_json(self, sent_idx, source='train'):\n",
    "        annotated = self.get_annotated_sent(sent_idx, source)\n",
    "        utterance = {u'text':unicode(' '.join([word for word,label in annotated])),\n",
    "                 u'intent':'None',\n",
    "                 u'entities':[]}\n",
    "        entity = {u'entity':'',u'startPos':0,u'endPos':0}\n",
    "        for i,item in enumerate(annotated):\n",
    "            current_entity = ''\n",
    "            if item[1].startswith('B'):\n",
    "                entity['startPos'] = i\n",
    "                current_entity = item[1].split('-')[1]\n",
    "                entity['entity'] = self.entities[current_entity] + '::' + current_entity\n",
    "                if i+1>=len(annotated) or annotated[i+1][1]=='O':\n",
    "                    entity['endPos'] = i\n",
    "                    utterance['entities'].append(entity)\n",
    "                    entity = {u'entity':'',u'startPos':0,u'endPos':0}\n",
    "                    current_entity = ''\n",
    "                    continue\n",
    "            elif item[1].startswith('I'):\n",
    "                if i+1>=len(annotated) or annotated[i+1][1]=='O':\n",
    "                    entity['endPos'] = i\n",
    "                    utterance['entities'].append(entity)\n",
    "                    entity = {u'entity':'',u'startPos':0,u'endPos':0}\n",
    "                    current_entity = ''\n",
    "                else: continue\n",
    "            else: continue\n",
    "        return utterance \n",
    "    \n",
    "    def populate_utterances(self, luis_json, num_utterances=2000):\n",
    "        # assuming luis_json is an exported app which doesn't have many labeled sents.\n",
    "        for i in xrange(num_utterances):\n",
    "            luis_json['utterances'].append(self.get_utterance_json(i))\n",
    "        return luis_json\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atis = ATIS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'entities': [{u'endPos': 5,\n",
       "   u'entity': u'from_loc::airline_name',\n",
       "   u'startPos': 5},\n",
       "  {u'endPos': 7, u'entity': u'flight::flight_number', u'startPos': 7},\n",
       "  {u'endPos': 10, u'entity': u'from_loc::fromloc.city_name', u'startPos': 9},\n",
       "  {u'endPos': 14,\n",
       "   u'entity': u'stop_to_loc::toloc.city_name',\n",
       "   u'startPos': 12}],\n",
       " u'intent': 'None',\n",
       " u'text': u'what aircraft is used on delta flight DIGITDIGITDIGITDIGIT from kansas city to salt lake city'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atis.get_utterance_json(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_ojoatis = atis.populate_utterances(ojoatis)\n",
    "''' FORMAT:\n",
    "{u'actions': [],\n",
    " u'bing_entities': [],\n",
    " u'composites': [],\n",
    " u'culture': u'en-us',\n",
    " u'desc': u'ner',\n",
    " u'entities': [{u'children': [u'arrive_time.end_time',\n",
    "    u'arrive_time.period_mod',\n",
    "    u'arrive_time.period_of_day',\n",
    "    u'arrive_time.start_time',\n",
    "    u'arrive_time.time_relative',\n",
    "    u'arrive_time.time'],\n",
    "   u'name': u'arrive_time'},\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('new_ojoatis.json', 'w') as f:\n",
    "     json.dump(new_ojoatis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'O'),\n",
       " ('flights', 'O'),\n",
       " ('leave', 'O'),\n",
       " ('atlanta', 'B-fromloc.city_name'),\n",
       " ('at', 'O'),\n",
       " ('about', 'B-depart_time.time_relative'),\n",
       " ('DIGIT', 'B-depart_time.time'),\n",
       " ('in', 'O'),\n",
       " ('the', 'O'),\n",
       " ('afternoon', 'B-depart_time.period_of_day'),\n",
       " ('and', 'O'),\n",
       " ('arrive', 'O'),\n",
       " ('in', 'O'),\n",
       " ('san', 'B-toloc.city_name'),\n",
       " ('francisco', 'I-toloc.city_name')]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE: LABELED DATA\n",
    "zip(map(atis.idx2words.get,atis.valid_set[0][0]),\n",
    "    map(atis.idx2labels.get,atis.valid_set[2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Facilities for Importing New Trained Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import luis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = luis.Luis(url=\"https://api.projectoxford.ai/luis/v1/application?id=e13e2ede-be9b-46cf-a568-7a3d92c4fcba&subscription-key=952396816ccf4d869657b9ef49533fb6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST: valid sentence 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'entities': [{u'endPos': 3,\n",
       "   u'entity': u'from_loc::fromloc.city_name',\n",
       "   u'startPos': 3},\n",
       "  {u'endPos': 6,\n",
       "   u'entity': u'depart_time_meal::depart_time.time',\n",
       "   u'startPos': 6},\n",
       "  {u'endPos': 9,\n",
       "   u'entity': u'depart_time_meal::depart_time.period_of_day',\n",
       "   u'startPos': 9},\n",
       "  {u'endPos': 14,\n",
       "   u'entity': u'stop_to_loc::toloc.city_name',\n",
       "   u'startPos': 13}],\n",
       " u'intent': 'None',\n",
       " u'text': u'what flights leave atlanta at about DIGIT in the afternoon and arrive in san francisco'}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val0_true = atis.get_utterance_json(0,source='valid')\n",
    "val0_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val0_luispy = l.analyze(val0_raw).entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Entity entity=u'atlanta' type=u'from_loc::fromloc.city_name' score=0.9590335 start_index=19 end_index=25>,\n",
       " <Entity entity=u'afternoon' type=u'depart_time_meal::depart_time.period_of_day' score=0.856796861 start_index=49 end_index=57>,\n",
       " <Entity entity=u'san francisco' type=u'stop_to_loc::toloc.city_name' score=0.871793866 start_index=73 end_index=85>]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val0_luispy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'entities': [{u'endPos': 3,\n",
       "   u'entity': u'from_loc::fromloc.city_name',\n",
       "   u'startPos': 3},\n",
       "  {u'endPos': 6,\n",
       "   u'entity': u'depart_time_meal::depart_time.time',\n",
       "   u'startPos': 6},\n",
       "  {u'endPos': 9,\n",
       "   u'entity': u'depart_time_meal::depart_time.period_of_day',\n",
       "   u'startPos': 9},\n",
       "  {u'endPos': 14,\n",
       "   u'entity': u'stop_to_loc::toloc.city_name',\n",
       "   u'startPos': 13}],\n",
       " u'intent': 'None',\n",
       " u'text': u'what flights leave atlanta at about DIGIT in the afternoon and arrive in san francisco'}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val0_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ================================ ATIS => [ (ent_txt: '..', ent_lb: '..'), (..), ..] ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'entities': [{u'endPos': 3,\n",
       "   u'entity': u'from_loc::fromloc.city_name',\n",
       "   u'startPos': 3},\n",
       "  {u'endPos': 6,\n",
       "   u'entity': u'depart_time_meal::depart_time.time',\n",
       "   u'startPos': 6},\n",
       "  {u'endPos': 9,\n",
       "   u'entity': u'depart_time_meal::depart_time.period_of_day',\n",
       "   u'startPos': 9},\n",
       "  {u'endPos': 14,\n",
       "   u'entity': u'stop_to_loc::toloc.city_name',\n",
       "   u'startPos': 13}],\n",
       " u'intent': 'None',\n",
       " u'text': u'what flights leave atlanta at about DIGIT in the afternoon and arrive in san francisco'}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val0_true = atis.get_utterance_json(0,source='valid')\n",
    "val0_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def utterance_json_to_entities_list(utterance):\n",
    "    text = utterance['text'].split()\n",
    "    pairs = []\n",
    "    for entity in utterance['entities']:\n",
    "        pairs.append((' '.join(text[entity['startPos']:entity['endPos']+1]),\n",
    "                      entity['entity']))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'atlanta', u'from_loc::fromloc.city_name'),\n",
       " (u'DIGIT', u'depart_time_meal::depart_time.time'),\n",
       " (u'afternoon', u'depart_time_meal::depart_time.period_of_day'),\n",
       " (u'san francisco', u'stop_to_loc::toloc.city_name')]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_json_to_entities_list(val0_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ================================ LUISPY => [ (ent_txt: '..', ent_lb: '..'), (..), ..] ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Entity entity=u'atlanta' type=u'from_loc::fromloc.city_name' score=0.9590335 start_index=19 end_index=25>,\n",
       " <Entity entity=u'afternoon' type=u'depart_time_meal::depart_time.period_of_day' score=0.856796861 start_index=49 end_index=57>,\n",
       " <Entity entity=u'san francisco' type=u'stop_to_loc::toloc.city_name' score=0.871793866 start_index=73 end_index=85>]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val0_luispy = l.analyze(val0_raw).entities\n",
    "val0_luispy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def luispy_to_entities_list(luispy_entities):\n",
    "    pairs = []\n",
    "    for entity in luispy_entities:\n",
    "        entity_info = str(entity).split(\"=\") \n",
    "            # ['<Entity entity',\n",
    "            #  \"u'san francisco' type\",\n",
    "            #  \"u'stop_to_loc::toloc.city_name' score\",\n",
    "            #  '0.871793866 start_index',\n",
    "            #  '73 end_index',\n",
    "            #  '85>']\n",
    "        pairs.append((entity_info[1].split('\\'')[1],\n",
    "                      entity_info[2].split()[0][2:-1]))\n",
    "            # tuple: (ent_text: ..., ent_label: ...)\n",
    "            # entity_info[1].split('\\''): ['u', 'san francisco', ' type']\n",
    "            # entity_info[2].split()[0][2:-1]: 'stop_to_loc::toloc.city_name'\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atlanta', 'from_loc::fromloc.city_name'),\n",
       " ('afternoon', 'depart_time_meal::depart_time.period_of_day'),\n",
       " ('san francisco', 'stop_to_loc::toloc.city_name')]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luispy_to_entities_list(val0_luispy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### ================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SIMILARITY between true and hat: JACCARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRUE:\n",
    "'''\n",
    "[(u'atlanta', u'from_loc::fromloc.city_name'),\n",
    " (u'DIGIT', u'depart_time_meal::depart_time.time'),\n",
    " (u'afternoon', u'depart_time_meal::depart_time.period_of_day'),\n",
    " (u'san francisco', u'stop_to_loc::toloc.city_name')]\n",
    "'''\n",
    "# HAT:\n",
    "'''\n",
    "[('atlanta', 'from_loc::fromloc.city_name'),\n",
    " ('afternoon', 'depart_time_meal::depart_time.period_of_day'),\n",
    " ('san francisco', 'stop_to_loc::toloc.city_name')]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(u'atlanta', u'from_loc::fromloc.city_name') == ('atlanta', 'from_loc::fromloc.city_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true = [(u'atlanta', u'from_loc::fromloc.city_name'),\n",
    " (u'DIGIT', u'depart_time_meal::depart_time.time'),\n",
    " (u'afternoon', u'depart_time_meal::depart_time.period_of_day'),\n",
    " (u'san francisco', u'stop_to_loc::toloc.city_name')]\n",
    "hat = [('atlanta', 'from_loc::fromloc.city_name'),\n",
    " ('afternoon', 'depart_time_meal::depart_time.period_of_day'),\n",
    " ('san francisco', 'stop_to_loc::toloc.city_name')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(true,hat):\n",
    "    return len(set(true).intersection(set(hat))) / \\\n",
    "               float(len(set(true).union(set(hat))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard(true,hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('afternoon', 'depart_time_meal::depart_time.period_of_day'),\n",
       " ('atlanta', 'from_loc::fromloc.city_name'),\n",
       " ('san francisco', 'stop_to_loc::toloc.city_name')}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(true).intersection(set(hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(u'DIGIT', u'depart_time_meal::depart_time.time'),\n",
       " (u'afternoon', u'depart_time_meal::depart_time.period_of_day'),\n",
       " (u'atlanta', u'from_loc::fromloc.city_name'),\n",
       " (u'san francisco', u'stop_to_loc::toloc.city_name')}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(true).union(set(hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. 100 Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val100_raw = [atis.get_utterance_json(i,source='valid') for i in xrange(100)] # from atis (train=998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val100_true = [utterance_json_to_entities_list(utterance) for utterance in val100_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed 0 sentences\n",
      "... processed 10 sentences\n",
      "... processed 20 sentences\n",
      "... processed 30 sentences\n",
      "... processed 40 sentences\n",
      "... processed 50 sentences\n",
      "... processed 60 sentences\n",
      "... processed 70 sentences\n",
      "... processed 80 sentences\n",
      "... processed 90 sentences\n",
      "CPU times: user 2.22 s, sys: 104 ms, total: 2.32 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val100_hat = []\n",
    "for i in xrange(100):\n",
    "    val_hat = l.analyze(val100_raw[i]['text']).entities\n",
    "    val100_hat.append(luispy_to_entities_list(val_hat))\n",
    "    if i%10==0:\n",
    "        print \"... processed %d sentences\" % i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737619047619\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "val100_jaccard = [jaccard(true,hat) for true,hat in zip(val100_true,val100_hat)]\n",
    "print np.mean(val100_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'atlanta', u'from_loc::fromloc.city_name'),\n",
       "  (u'DIGIT', u'depart_time_meal::depart_time.time'),\n",
       "  (u'afternoon', u'depart_time_meal::depart_time.period_of_day'),\n",
       "  (u'san francisco', u'stop_to_loc::toloc.city_name')],\n",
       " [(u'canadian airlines international', u'from_loc::airline_name')],\n",
       " [(u'earliest', u'flight::flight_mod'),\n",
       "  (u'boston', u'from_loc::fromloc.city_name'),\n",
       "  (u'atlanta', u'stop_to_loc::toloc.city_name')],\n",
       " [(u'us air', u'from_loc::airline_name'),\n",
       "  (u'atlanta', u'from_loc::fromloc.city_name'),\n",
       "  (u'boston', u'stop_to_loc::toloc.city_name')],\n",
       " [(u'round trips', u'flight::round_trip'),\n",
       "  (u'dallas', u'from_loc::fromloc.city_name'),\n",
       "  (u'baltimore', u'stop_to_loc::toloc.city_name')]]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val100_true[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('atlanta', 'from_loc::fromloc.city_name'),\n",
       "  ('afternoon', 'depart_time_meal::depart_time.period_of_day'),\n",
       "  ('san francisco', 'stop_to_loc::toloc.city_name')],\n",
       " [],\n",
       " [('earliest', 'flight::flight_mod'),\n",
       "  ('boston', 'from_loc::fromloc.city_name'),\n",
       "  ('atlanta', 'stop_to_loc::toloc.city_name')],\n",
       " [('us air', 'from_loc::airline_name'),\n",
       "  ('atlanta', 'from_loc::fromloc.city_name'),\n",
       "  ('boston', 'stop_to_loc::toloc.city_name')],\n",
       " [('dallas', 'from_loc::fromloc.city_name'),\n",
       "  ('baltimore', 'stop_to_loc::toloc.city_name')]]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val100_hat[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(trues,hats):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for true,hat in zip(trues,hats):\n",
    "        entries = set(true+hat) # all unique entries for this pair\n",
    "        for entry in entries:\n",
    "            if entry in hat and entry in true: tp += 1\n",
    "            elif entry in hat and entry not in true: fp += 1\n",
    "            elif entry in true and entry not in hat: fn += 1\n",
    "            else: pass\n",
    "    prec = tp/(tp+fp)\n",
    "    rec = tp/(tp+fn)\n",
    "    print \"Precision: %.2f%% | Recall: %.2f%% | F1: %.2f\" % (prec*100, rec*100, ((2*prec*rec)/(prec+rec))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING ON LUIS Lite (997 sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 88.00% | Recall: 78.29% | F1: 82.86\n"
     ]
    }
   ],
   "source": [
    "f1(val100_true,val100_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'atlanta', u'from_loc::fromloc.city_name'),\n",
       " (u'DIGIT', u'depart_time_meal::depart_time.time'),\n",
       " (u'afternoon', u'depart_time_meal::depart_time.period_of_day'),\n",
       " (u'san francisco', u'stop_to_loc::toloc.city_name')]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val100_true[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atlanta', 'from_loc::fromloc.city_name'),\n",
       " ('afternoon', 'depart_time_meal::depart_time.period_of_day'),\n",
       " ('san francisco', 'stop_to_loc::toloc.city_name')]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val100_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(u'DIGIT', u'depart_time_meal::depart_time.time'),\n",
       " (u'afternoon', u'depart_time_meal::depart_time.period_of_day'),\n",
       " (u'atlanta', u'from_loc::fromloc.city_name'),\n",
       " (u'san francisco', u'stop_to_loc::toloc.city_name')}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(val100_true[0]+val100_hat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAINING ON LUIS Medium (4332 sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = luis.Luis(url=\"https://api.projectoxford.ai/luis/v1/application?id=b08f059d-299a-4223-aa3d-06d19964d2e9&subscription-key=952396816ccf4d869657b9ef49533fb6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... processed 0 sentences\n",
      "... processed 10 sentences\n",
      "... processed 20 sentences\n",
      "... processed 30 sentences\n",
      "... processed 40 sentences\n",
      "... processed 50 sentences\n",
      "... processed 60 sentences\n",
      "... processed 70 sentences\n",
      "... processed 80 sentences\n",
      "... processed 90 sentences\n",
      "CPU times: user 2.32 s, sys: 106 ms, total: 2.42 s\n",
      "Wall time: 35.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tst100_raw = [atis.get_utterance_json(i,source='test') for i in xrange(100)] # from atis (train=998)\n",
    "tst100_true = [utterance_json_to_entities_list(utterance) for utterance in tst100_raw]\n",
    "tst100_hat = []\n",
    "for i in xrange(100):\n",
    "    tst_hat = l.analyze(tst100_raw[i]['text']).entities\n",
    "    tst100_hat.append(luispy_to_entities_list(tst_hat))\n",
    "    if i%10==0:\n",
    "        print \"... processed %d sentences\" % i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716166666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tst100_jaccard = [jaccard(true,hat) for true,hat in zip(tst100_true,tst100_hat)]\n",
    "print np.mean(tst100_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 81.82% | Recall: 78.79% | F1: 80.27\n"
     ]
    }
   ],
   "source": [
    "f1(tst100_true,tst100_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUIS <=> RNN Data\n",
    "\n",
    "* **Task I:** Translating between LUIS utterances and RNN data.\n",
    "* **Task II:** Evaluation (MAYBE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = [{u'children': [u'arrive_time.end_time',\n",
    "                   u'arrive_time.period_mod',\n",
    "                   u'arrive_time.period_of_day',\n",
    "                   u'arrive_time.start_time',\n",
    "                   u'arrive_time.time_relative',\n",
    "                   u'arrive_time.time'],\n",
    "                  u'name': u'arrive_time'},\n",
    "                 {u'children': [u'depart_time.end_time',\n",
    "                   u'depart_time.period_mod',\n",
    "                   u'depart_time.period_of_day',\n",
    "                   u'depart_time.start_time',\n",
    "                   u'depart_time.time',\n",
    "                   u'depart_time.time_relative',\n",
    "                   u'meal',\n",
    "                   u'meal_description'],\n",
    "                  u'name': u'depart_time_meal'},\n",
    "                 {u'children': [u'return_date.date_relative',\n",
    "                   u'return_date.day_name',\n",
    "                   u'return_date.day_number',\n",
    "                   u'return_date.month_name',\n",
    "                   u'return_date.today_relative',\n",
    "                   u'return_time.period_mod',\n",
    "                   u'return_time.period_of_day',\n",
    "                   u'cost_relative',\n",
    "                   u'fare_amount'],\n",
    "                  u'name': u'return_cost'},\n",
    "                 {u'children': [u'flight',\n",
    "                   u'flight_days',\n",
    "                   u'flight_mod',\n",
    "                   u'flight_number',\n",
    "                   u'flight_stop',\n",
    "                   u'flight_time',\n",
    "                   u'round_trip',\n",
    "                   u'compartment',\n",
    "                   u'economy',\n",
    "                   u'connect'],\n",
    "                  u'name': u'flight'},\n",
    "                 {u'children': [u'fromloc.airport_code',\n",
    "                   u'fromloc.airport_name',\n",
    "                   u'fromloc.city_name',\n",
    "                   u'fromloc.state_code',\n",
    "                   u'fromloc.state_name',\n",
    "                   u'airline_name',\n",
    "                   u'airport_name',\n",
    "                   u'city_name',\n",
    "                   u'state_name'],\n",
    "                  u'name': u'from_loc'},\n",
    "                 {u'children': [u'aircraft_code',\n",
    "                   u'airline_code',\n",
    "                   u'airport_code',\n",
    "                   u'booking_class',\n",
    "                   u'fare_basis_code',\n",
    "                   u'meal_code',\n",
    "                   u'restriction_code',\n",
    "                   u'state_code',\n",
    "                   u'transport_type',\n",
    "                   u'class_type'],\n",
    "                  u'name': u'codes_types'},\n",
    "                 {u'children': [u'day_name',\n",
    "                   u'day_number',\n",
    "                   u'days_code',\n",
    "                   u'month_name',\n",
    "                   u'period_of_day',\n",
    "                   u'time',\n",
    "                   u'time_relative',\n",
    "                   u'today_relative'],\n",
    "                  u'name': u'misc_date_time'},\n",
    "                 {u'children': [u'depart_date.date_relative',\n",
    "                   u'depart_date.day_name',\n",
    "                   u'depart_date.day_number',\n",
    "                   u'depart_date.month_name',\n",
    "                   u'depart_date.today_relative',\n",
    "                   u'depart_date.year',\n",
    "                   u'mod',\n",
    "                   u'or'],\n",
    "                  u'name': u'depart_date_mod_or'},\n",
    "                 {u'children': [u'stoploc.airport_code',\n",
    "                   u'stoploc.airport_name',\n",
    "                   u'stoploc.city_name',\n",
    "                   u'stoploc.state_code',\n",
    "                   u'toloc.airport_code',\n",
    "                   u'toloc.airport_name',\n",
    "                   u'toloc.city_name',\n",
    "                   u'toloc.country_name',\n",
    "                   u'toloc.state_code',\n",
    "                   u'toloc.state_name'],\n",
    "                  u'name': u'stop_to_loc'},\n",
    "                 {u'children': [u'arrive_date.date_relative',\n",
    "                   u'arrive_date.day_name',\n",
    "                   u'arrive_date.day_number',\n",
    "                   u'arrive_date.month_name',\n",
    "                   u'arrive_date.today_relative'],\n",
    "                  u'name': u'arrive_date'}\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Translator: Babel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Babel:\n",
    "    \n",
    "    def __init__(self, dicts_path='/Users/jacobsw/Downloads/atis.fold1.pkl.gz'):\n",
    "        f = gzip.open(dicts_path,'rb')\n",
    "        _,_,_,self.dicts = pickle.load(f)\n",
    "        f.close()\n",
    "    \n",
    "    def luis2data(self, luis_utterances):\n",
    "        # IN: luis utterances\n",
    "        #  {u'entities': [{u'endPos': 5,\n",
    "        #    u'entity': u'from_loc::airline_name',\n",
    "        #    u'startPos': 5},\n",
    "        #   {u'endPos': 7, u'entity': u'flight::flight_number', u'startPos': 7},\n",
    "        #   {u'endPos': 10, u'entity': u'from_loc::fromloc.city_name', u'startPos': 9},\n",
    "        #   {u'endPos': 14,\n",
    "        #    u'entity': u'stop_to_loc::toloc.city_name',\n",
    "        #    u'startPos': 12}],\n",
    "        #  u'intent': u'None',\n",
    "        #  u'text': u'what aircraft is used on delta flight DIGITDIGITDIGITDIGIT from kansas city to salt lake city'}\n",
    "        # OUT: training data (w/ labels)\n",
    "        sents, labels = [],[]\n",
    "        for utterance in luis_utterances:\n",
    "            sents.append(np.asarray(map(self.dicts['words2idx'].get,\n",
    "                                        utterance['text'].split()),dtype='int32'))\n",
    "            label = ['O' for _ in utterance['text'].split()]\n",
    "            for entity in utterance['entities']:\n",
    "                label[entity['startPos']]='B-'+entity['entity'].split('::')[1]\n",
    "                if entity['startPos']!=entity['endPos']: \n",
    "                    for i in range(entity['startPos']+1,entity['endPos']+1):\n",
    "                        label[i] = 'I-'+entity['entity'].split('::')[1]\n",
    "            labels.append(label)        \n",
    "        return (sents,labels)\n",
    "    \n",
    "    def data2luis(self, data, entities):\n",
    "        def entities_dict_transform(entities):\n",
    "            new_dict = {}\n",
    "            for entry in entities:\n",
    "                for child in entry['children']:\n",
    "                    new_dict[child] = entry['name']\n",
    "            return new_dict\n",
    "        entities = entities_dict_transform(entities)\n",
    "        self.idx2labels = {idx:label for (label,idx) in self.dicts['labels2idx'].iteritems()}\n",
    "        self.idx2words = {idx:word for (word,idx) in self.dicts['words2idx'].iteritems()}\n",
    "        utterances = []\n",
    "        for sent_idx in xrange(len(data[0])):\n",
    "            annotated = zip(map(self.idx2words.get,data[0][sent_idx]),\n",
    "                            map(self.idx2labels.get,data[2][sent_idx]))\n",
    "            utterance = {u'text':unicode(' '.join([word for word,label in annotated])),\n",
    "                         u'intent':'None', u'entities':[]}\n",
    "            entity = {u'entity':'',u'startPos':0,u'endPos':0}\n",
    "            for i,item in enumerate(annotated):\n",
    "                current_entity = ''\n",
    "                if item[1].startswith('B'):\n",
    "                    entity['startPos'] = i\n",
    "                    current_entity = item[1].split('-')[1]\n",
    "                    entity['entity'] = entities[current_entity] + '::' + current_entity\n",
    "                    if i+1>=len(annotated) or annotated[i+1][1]=='O':\n",
    "                        entity['endPos'] = i\n",
    "                        utterance['entities'].append(entity)\n",
    "                        entity = {u'entity':'',u'startPos':0,u'endPos':0}\n",
    "                        current_entity = ''\n",
    "                        continue\n",
    "                elif item[1].startswith('I'):\n",
    "                    if i+1>=len(annotated) or annotated[i+1][1]=='O':\n",
    "                        entity['endPos'] = i\n",
    "                        utterance['entities'].append(entity)\n",
    "                        entity = {u'entity':'',u'startPos':0,u'endPos':0}\n",
    "                        current_entity = ''\n",
    "                    else: continue\n",
    "                else: continue\n",
    "            utterances.append(utterance)\n",
    "        return utterances\n",
    "    \n",
    "    def data2uploadable(self, data, entities):\n",
    "        def entities_dict_transform(entities):\n",
    "            new_dict = {}\n",
    "            for entry in entities:\n",
    "                for child in entry['children']:\n",
    "                    new_dict[child] = entry['name']\n",
    "            return new_dict\n",
    "        entities = entities_dict_transform(entities)\n",
    "        self.idx2labels = {idx:label for (label,idx) in self.dicts['labels2idx'].iteritems()}\n",
    "        self.idx2words = {idx:word for (word,idx) in self.dicts['words2idx'].iteritems()}\n",
    "        def word_index_in_string(w_idx, w, s, mode='start'):\n",
    "            if mode=='start': return len(' '.join(s[:w_idx]))+1\n",
    "            elif mode=='end': return len(' '.join(s[:w_idx]))+len(w)\n",
    "            else: return (len(' '.join(s[:w_idx]))+1, len(' '.join(s[:w_idx]))+len(w))\n",
    "        def make_label(entity_type, start_token, end_token):\n",
    "            return {\"EntityType\": entity_type,\"StartToken\": start_token,\"EndToken\": end_token,\"IsBuiltIn\": 'false'}\n",
    "            # label_template = {\"EntityType\": \"\",\"StartToken\": 0,\"EndToken\": 0,\"IsBuiltIn\": 'false'}      \n",
    "        def make_sent(example_text):\n",
    "            return {\"SelectedIntentName\": \"None\",\"ExampleText\": example_text,\"EntityLabels\": []}\n",
    "            # sent_template = {\"SelectedIntentName\": \"None\",\"ExampleText\": \"\",\"EntityLabels\": []}\n",
    "        sents = []\n",
    "        for sent_idx in xrange(len(data[0])):\n",
    "            text = map(self.idx2words.get,data[0][sent_idx])\n",
    "            labels = map(self.idx2labels.get,data[2][sent_idx])\n",
    "            EntityType = \"\"\n",
    "            StartToken, EndToken = 0, 0\n",
    "            sent = make_sent(' '.join(text))\n",
    "            for i,l in enumerate(labels):\n",
    "                if l.startswith('B'):\n",
    "                    EntityType = str(entities[l.split('-')[1]] + '::' + l.split('-')[1])\n",
    "                    if i==len(labels)-1 or labels[i+1]=='O':\n",
    "                        StartToken, EndToken = word_index_in_string(i,text[i],text,mode='both')\n",
    "                        sent['EntityLabels'].append(make_label(EntityType,StartToken,EndToken))\n",
    "                        EntityType,StartToken,EndToken = \"\",0,0\n",
    "                    StartToken = word_index_in_string(i,text[i],text,mode='start')\n",
    "                elif l.startswith('I'):\n",
    "                    if i==len(labels)-1 or labels[i+1]=='O':\n",
    "                        EndToken = word_index_in_string(i,text[i],text,mode='end') \n",
    "                        sent['EntityLabels'].append(make_label(EntityType,StartToken,EndToken))\n",
    "                        EntityType,StartToken,EndToken = \"\",0,0\n",
    "                    else: pass\n",
    "                else: pass\n",
    "            sents.append(sent)\n",
    "        return sents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD TESTORS\n",
    "f = gzip.open('/Users/jacobsw/Downloads/atis.fold1.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set, dicts = pickle.load(f)\n",
    "f.close()\n",
    "import os\n",
    "with open('/Users/jacobsw/Desktop/new_ojoatis.json') as json_file:\n",
    "    ojoatis = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbl = Babel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'entities': [{u'endPos': 5,\n",
       "   u'entity': u'from_loc::fromloc.city_name',\n",
       "   u'startPos': 5},\n",
       "  {u'endPos': 7, u'entity': u'stop_to_loc::toloc.city_name', u'startPos': 7},\n",
       "  {u'endPos': 9,\n",
       "   u'entity': u'depart_date_mod_or::depart_date.day_name',\n",
       "   u'startPos': 9}],\n",
       " u'intent': 'None',\n",
       " u'text': u'i want to go from boston to atlanta on monday'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN DATA => LUIS UTTERANCES\n",
    "data = train_set\n",
    "bbl.data2luis(data, entities)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EntityLabels': [{'EndToken': 23,\n",
       "   'EntityType': 'from_loc::fromloc.city_name',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 18},\n",
       "  {'EndToken': 34,\n",
       "   'EntityType': 'stop_to_loc::toloc.city_name',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 28},\n",
       "  {'EndToken': 44,\n",
       "   'EntityType': 'depart_date_mod_or::depart_date.day_name',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 39}],\n",
       " 'ExampleText': 'i want to go from boston to atlanta on monday',\n",
       " 'SelectedIntentName': 'None'}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN DATA => LUIS UPLOADABLES\n",
    "bbl.data2uploadable(data, entities)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[554  23 241 534 358 136 193  11 208 251 104 502 413 256 104]\n",
      "[232 542 502 213 208  77 502  64 358 317]\n"
     ]
    }
   ],
   "source": [
    "# LUIS UTTERANCES => RNN DATA\n",
    "luis_utterances = ojoatis['utterances']\n",
    "print bbl.luis2data(luis_utterances)[0][0]\n",
    "print bbl.luis2data(luis_utterances)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Upload to LUIS App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import httplib, urllib, base64\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LuisUploader:\n",
    "    \n",
    "    def __init__(self, appid, subscription_key):\n",
    "        self.appid = appid\n",
    "        self.subscription_key = subscription_key\n",
    "    \n",
    "    def upload(self, luis_uploadables):\n",
    "        # luis_uploadables: a list of {}'s in the form of \n",
    "        #     {\n",
    "        #      \"SelectedIntentName\": \"None\",\n",
    "        #      \"ExampleText\": \"I want to fly to london\",\n",
    "        #      \"EntityLabels\": [\n",
    "        #        {\n",
    "        #         \"EntityType\": \"stop_to_loc::toloc.city_name\",\n",
    "        #         \"StartToken\": 17,\n",
    "        #         \"EndToken\": 22,\n",
    "        #         \"IsBuiltIn\": 'false'\n",
    "        #        }\n",
    "        #      ]\n",
    "        #    }\n",
    "        requests.post(\"https://api.projectoxford.ai/luis/v1.0/prog/apps/%s/examples\" % self.appid, \n",
    "             headers={\"Ocp-Apim-Subscription-Key\": self.subscription_key},\n",
    "             json=luis_uploadables)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = gzip.open('/Users/jacobsw/Downloads/atis.fold1.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set, dicts = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "appid = 'b08f059d-299a-4223-aa3d-06d19964d2e9'\n",
    "subscription_key = '952396816ccf4d869657b9ef49533fb6'\n",
    "uploader = LuisUploader(appid, subscription_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbl = Babel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD TRAIN\n",
    "uploadables = bbl.data2uploadable(train_set, entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EntityLabels': [{'EndToken': 29,\n",
       "   'EntityType': 'from_loc::airline_name',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 25},\n",
       "  {'EndToken': 57,\n",
       "   'EntityType': 'flight::flight_number',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 38},\n",
       "  {'EndToken': 74,\n",
       "   'EntityType': 'from_loc::fromloc.city_name',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 64},\n",
       "  {'EndToken': 92,\n",
       "   'EntityType': 'stop_to_loc::toloc.city_name',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 79}],\n",
       " 'ExampleText': 'what aircraft is used on delta flight DIGITDIGITDIGITDIGIT from kansas city to salt lake city',\n",
       " 'SelectedIntentName': 'None'}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploadables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD VALID TOO!\n",
    "uploadables_valid = bbl.data2uploadable(valid_set, entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EntityLabels': [{'EndToken': 25,\n",
       "   'EntityType': 'from_loc::fromloc.city_name',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 19},\n",
       "  {'EndToken': 40,\n",
       "   'EntityType': 'depart_time_meal::depart_time.time',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 36},\n",
       "  {'EndToken': 57,\n",
       "   'EntityType': 'depart_time_meal::depart_time.period_of_day',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 49},\n",
       "  {'EndToken': 85,\n",
       "   'EntityType': 'stop_to_loc::toloc.city_name',\n",
       "   'IsBuiltIn': 'false',\n",
       "   'StartToken': 73}],\n",
       " 'ExampleText': 'what flights leave atlanta at about DIGIT in the afternoon and arrive in san francisco',\n",
       " 'SelectedIntentName': 'None'}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploadables_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# counter = 0\n",
    "# for uploadable in uploadables0[8:]:\n",
    "#     uploader.upload([uploadable])\n",
    "#     counter += 1\n",
    "#     if counter % 10 == 0:\n",
    "#         print \"... %d uploaded\" % counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# USEFUL FUNCTIONS\n",
    "# \n",
    "# def post_luis_examples(app_id, subscription_key, obj):\n",
    "#     return requests.post(\"https://api.projectoxford.ai/luis/v1.0/prog/apps/%s/examples\" % app_id, \n",
    "#              headers={\"Ocp-Apim-Subscription-Key\": subscription_key},\n",
    "#              json=obj)\n",
    "# def get_luis_examples(app_id, subscription_key, skip=0, count=5):\n",
    "#     return requests.get(\"https://api.projectoxford.ai/luis/v1.0/prog/apps/%s/examples\" % app_id,\n",
    "#             headers={\"Ocp-Apim-Subscription-Key\": subscription_key},\n",
    "#             params={\"skip\":skip, \"count\": count})\n",
    "# from itertools import groupby\n",
    "# from numpy.random import randn\n",
    "# x = randn(100)\n",
    "# groups = groupby(enumerate(x), lambda t:t[0]/25)\n",
    "# g = next(groups)\n",
    "# g[0], list(g[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. RNN NER Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** TO RUN IN TERMINAL **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export PYTHONPATH=$PWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/jacobsw/Desktop/OJO/LUIS/is13-NER_MODELS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "import random\n",
    "\n",
    "from is13.data import load\n",
    "from is13.rnn.elman import model\n",
    "from is13.metrics.accuracy import conlleval\n",
    "from is13.utils.tools import shuffle, minibatch, contextwin\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation,\n",
    "                          TimeDistributed)\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_atis(k=3):    \n",
    "    train, valid, test, dic = load.atisfold(k)\n",
    "    idx2label = {i:l for l,i in dic['labels2idx'].iteritems()}\n",
    "    idx2word = {i:w for w,i in dic['words2idx'].iteritems()}\n",
    "    return (train, valid, test, dic, idx2label, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, valid, test, dic, idx2label, idx2word = load_atis()\n",
    "data = (train, valid, test, dic)\n",
    "indexation = (idx2label, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNNNER:\n",
    "    \n",
    "    def __init__(self, data, indexation=None, \n",
    "                 folder='/Users/jacobsw/Desktop/OJO/LUIS/is13-NER_MODELS/elman-forward',\n",
    "                 config={'lr':0.1,'verbose':1,'nhidden':100,'seed':345,\n",
    "                         'emb_dimension':100,'nepochs':50}):\n",
    "            # data = (train, valid, test, dic)\n",
    "            # indexation = (idx2label, idx2word)\n",
    "        self.config = config\n",
    "        self.folder = folder\n",
    "        if not os.path.exists(folder): os.mkdir(folder)          \n",
    "        self.train, self.valid, self.test, self.dic = data\n",
    "        if indexation:\n",
    "            self.idx2label, self.idx2word = indexation\n",
    "        self.__train()\n",
    "        \n",
    "    def __train(self):\n",
    "        \n",
    "        print \"... configuring data\"\n",
    "        train_lex, train_ne, train_y = self.train\n",
    "        valid_lex, valid_ne, valid_y = self.valid\n",
    "        test_lex, test_ne, test_y = self.test\n",
    "        vocsize = len(self.dic['words2idx'])\n",
    "        nclasses = len(dic['labels2idx'])\n",
    "        nsentences = len(train_lex)\n",
    "    \n",
    "        print \"... building model\"\n",
    "        np.random.seed(self.config['seed'])\n",
    "        random.seed(self.config['seed'])\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(vocsize, self.config['emb_dimension']))\n",
    "        model.add(SimpleRNN(self.config['nhidden'],activation='sigmoid',\n",
    "                            return_sequences=True))\n",
    "        model.add(TimeDistributed(Dense(output_dim=nclasses)))\n",
    "        model.add(Activation('softmax'))\n",
    "        sgd = SGD(lr=self.config['lr'], momentum=.0, decay=.0, nesterov=False)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "        \n",
    "        print \"... training model\"\n",
    "        best_f1 = -np.inf\n",
    "        for e in xrange(self.config['nepochs']):\n",
    "            shuffle([train_lex, train_ne, train_y], self.config['seed'])\n",
    "            self.config['ce'] = e\n",
    "#             tic = time.time()\n",
    "\n",
    "            if self.config['verbose']:\n",
    "                print \"... running epoch %i\" % e\n",
    "\n",
    "            for i in xrange(nsentences):\n",
    "                X = np.asarray([train_lex[i]])\n",
    "                Y = to_categorical(np.asarray(train_y[i])[:,np.newaxis],\n",
    "                                              nclasses)[np.newaxis,:,:]\n",
    "                if X.shape[1]==1: continue\n",
    "                model.train_on_batch(X,Y)\n",
    "#                 if self.config['verbose']:         \n",
    "#                     print '[learning] epoch %i >> %2.2f%%'%(e,(i+1)*100./nsentences), \\\n",
    "#                           'completed in %.2f (sec) <<\\r'%(time.time()-tic), \\\n",
    "#                           sys.stdout.flush()\n",
    "                    \n",
    "                            \n",
    "        predictions_test = [map(lambda x: self.idx2label[x], \\\n",
    "            model.predict_on_batch( \\\n",
    "            np.asarray([x])).argmax(2)[0]) \\\n",
    "            for x in test_lex]\n",
    "        groundtruth_test = [ map(lambda x: idx2label[x], y) for y in test_y ]\n",
    "        words_test = [ map(lambda x: idx2word[x], w) for w in test_lex]\n",
    "\n",
    "        predictions_valid = [map(lambda x: idx2label[x], \\\n",
    "            model.predict_on_batch( \\\n",
    "            np.asarray([x])).argmax(2)[0]) \\\n",
    "            for x in valid_lex]\n",
    "        groundtruth_valid = [ map(lambda x: self.idx2label[x], y) for y in valid_y ]\n",
    "        words_valid = [ map(lambda x: self.idx2word[x], w) for w in valid_lex]\n",
    "\n",
    "        # evaluation // compute the accuracy using conlleval.pl\n",
    "        res_test  = conlleval(predictions_test, groundtruth_test, words_test, self.folder + '/current.test.txt')\n",
    "        res_valid = conlleval(predictions_valid, groundtruth_valid, words_valid, self.folder + '/current.valid.txt')\n",
    "\n",
    "        if res_valid['f1'] > best_f1:\n",
    "            model.save_weights('best_model.h5', overwrite=True)\n",
    "            best_f1 = res_valid['f1']\n",
    "            if self.config['verbose']: \n",
    "                print 'NEW BEST: epoch', e, 'valid F1', res_valid['f1'], 'best test F1', res_test['f1'], ' '*20 \n",
    "            self.config['vf1'], self.config['vp'], self.config['vr'] = res_valid['f1'], res_valid['p'], res_valid['r'] \n",
    "            self.config['tf1'], self.config['tp'], self.config['tr'] = res_test['f1'],  res_test['p'],  res_test['r'] \n",
    "            self.config['be'] = e\n",
    "            subprocess.call(['mv', self.folder + '/current.test.txt', self.folder + '/best.test.txt'])\n",
    "            subprocess.call(['mv', self.folder + '/current.valid.txt', self.folder + '/best.valid.txt'])\n",
    "        else:\n",
    "            print ''\n",
    "\n",
    "        print 'BEST RESULT: epoch', e, 'valid F1', self.config['vf1'], 'best test F1', self.config['tf1'], 'with the model', self.folder         \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn = RNNNER(data,indexation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
