{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATIS Data (Spacy-Based Info Augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Define Info Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip, pickle\n",
    "import spacy\n",
    "from spacy.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_info(sent): \n",
    "    # assuming parser = spacy.English()\n",
    "    # sent is a list of words\n",
    "    if type(sent)==list: sent = ' '.join(sent)\n",
    "    parsed = parser(unicode(sent))# if type(sent)==str else parser(unicode(sent))\n",
    "    pos = [token.pos_ for token in parsed]\n",
    "    ner = ['none' if token.ent_type_=='' else token.ent_type_ for token in parsed]\n",
    "    dep_rel = [token.dep_ for token in parsed]\n",
    "    dep_head = [token.head.orth_ for token in parsed]\n",
    "    return pos, ner, dep_rel, dep_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/OJO/LUIS/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = gzip.open(path+'atis.fold0.pkl.gz','rb')\n",
    "train, valid, test, dicts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([554, 194, 268,  64,  62,  16,   8, 234, 481,  20,  40,  58, 234,\n",
       "       415, 205], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels2idx', 'tables2idx', 'words2idx']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts.keys() # 'tables2idx' is not used, since it's not derivable generally (atis-specific info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i2w = {i:w for w,i in dicts['words2idx'].iteritems()}\n",
    "i2l = {i:l for l,i in dicts['labels2idx'].iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'flights', 'leave', 'atlanta', 'at', 'about', 'DIGIT', 'in', 'the', 'afternoon', 'and', 'arrive', 'in', 'san', 'francisco']\n"
     ]
    }
   ],
   "source": [
    "print map(i2w.get, train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [map(i2w.get, encoded_sent) for encoded_sent in train[0]]\n",
    "X_test = [map(i2w.get, encoded_sent) for encoded_sent in test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'flights', 'leave', 'atlanta', 'at', 'about', 'DIGIT', 'in', 'the', 'afternoon', 'and', 'arrive', 'in', 'san', 'francisco']\n",
      "['i', 'would', 'like', 'to', 'find', 'a', 'flight', 'from', 'charlotte', 'to', 'las', 'vegas', 'that', 'makes', 'a', 'stop', 'in', 'st.', 'louis']\n"
     ]
    }
   ],
   "source": [
    "print X_train[0]\n",
    "print X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = [map(i2l.get, encoded_labels) for encoded_labels in train[2]]\n",
    "Y_test = [map(i2l.get, encoded_sent) for encoded_sent in test[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-depart_time.time_relative', 'B-depart_time.time', 'O', 'O', 'B-depart_time.period_of_day', 'O', 'O', 'O', 'B-toloc.city_name', 'I-toloc.city_name']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'O', 'O', 'O', 'O', 'B-stoploc.city_name', 'I-stoploc.city_name']\n"
     ]
    }
   ],
   "source": [
    "print Y_train[0]\n",
    "print Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dicts['labels2idx'].keys()) # 127 labels in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_info(sent): \n",
    "    # sent: a list of words.\n",
    "    # return: (words, pos, ner, dep_rel, dep_head).\n",
    "    pos, ner, dep_rel, dep_head = extract_info(sent)\n",
    "    return (sent, pos, ner, dep_rel, dep_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['what', 'flights', 'leave', 'atlanta', 'at', 'about', 'DIGIT', 'in', 'the', 'afternoon', 'and', 'arrive', 'in', 'san', 'francisco'], [u'ADJ', u'NOUN', u'VERB', u'ADV', u'ADP', u'ADP', u'PROPN', u'ADP', u'DET', u'NOUN', u'CONJ', u'VERB', u'ADP', u'PROPN', u'NOUN'], ['none', 'none', 'none', 'none', 'none', 'none', u'ORG', 'none', 'none', u'TIME', 'none', 'none', 'none', 'none', 'none'], [u'det', u'nsubj', u'ROOT', u'advmod', u'prep', u'nmod', u'pobj', u'prep', u'det', u'pobj', u'cc', u'conj', u'prep', u'compound', u'pobj'], [u'flights', u'leave', u'leave', u'at', u'leave', u'DIGIT', u'at', u'DIGIT', u'afternoon', u'in', u'leave', u'leave', u'arrive', u'francisco', u'in'])\n"
     ]
    }
   ],
   "source": [
    "print augment_info(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_augmented = [augment_info(sent) for sent in X_train]\n",
    "X_test_augmented = [augment_info(sent) for sent in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'flights', 'leave', 'atlanta', 'at', 'about', 'DIGIT', 'in', 'the', 'afternoon', 'and', 'arrive', 'in', 'san', 'francisco']\n",
      "[u'ADJ', u'NOUN', u'VERB', u'ADV', u'ADP', u'ADP', u'PROPN', u'ADP', u'DET', u'NOUN', u'CONJ', u'VERB', u'ADP', u'PROPN', u'NOUN']\n",
      "['none', 'none', 'none', 'none', 'none', 'none', u'ORG', 'none', 'none', u'TIME', 'none', 'none', 'none', 'none', 'none']\n",
      "[u'det', u'nsubj', u'ROOT', u'advmod', u'prep', u'nmod', u'pobj', u'prep', u'det', u'pobj', u'cc', u'conj', u'prep', u'compound', u'pobj']\n",
      "[u'flights', u'leave', u'leave', u'at', u'leave', u'DIGIT', u'at', u'DIGIT', u'afternoon', u'in', u'leave', u'leave', u'arrive', u'francisco', u'in']\n"
     ]
    }
   ],
   "source": [
    "for entry in X_train_augmented[0]:\n",
    "    print entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyparsing import StringEnd, oneOf, FollowedBy, Optional, ZeroOrMore, SkipTo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = ['anti','de','dis','en','em','fore','in','im','il','ir',\n",
    "          'inter','mid','mis','non','over','pre','re','semi','sub',\n",
    "          'super','trans','un','under']\n",
    "suffix = ['able','ible','al','ial','ed','en','er','est','ful','ic',\n",
    "          'ing','ion','tion','ation','ition','ity','ty','ive','ative',\n",
    "          'itive','less','ly','ment','ness','ous','eous','ious','s',\n",
    "          'es','y','ism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Featurize:\n",
    "    \n",
    "    def __init__(self, prefix=[], suffix=[]): # lists of pfx/sfx.\n",
    "        self.prefix = prefix\n",
    "        self.suffix = suffix\n",
    "        end_of_string = StringEnd()\n",
    "        pfx_pyp_regex = oneOf(' '.join(prefix))\n",
    "        sfx_pyp_regex = oneOf(' '.join(suffix)) + FollowedBy(end_of_string)\n",
    "        self.template = (ZeroOrMore(pfx_pyp_regex)('prefix') +\n",
    "                         SkipTo(sfx_pyp_regex | end_of_string)('root') + \n",
    "                         Optional(sfx_pyp_regex)('suffix'))              \n",
    "        self.afx = lambda word: self.template.parseString(word)\n",
    "        self.feat_set = {'pfx': lambda w_idx,datum: self.afx(datum[0][w_idx]).prefix[0] \\\n",
    "                                     if self.afx(datum[0][w_idx]).prefix!='' else 'no_pfx',\n",
    "                         'sfx': lambda w_idx,datum: self.afx(datum[0][w_idx]).suffix[0] \\\n",
    "                                     if self.afx(datum[0][w_idx]).suffix!='' else 'no_sfx',\n",
    "                         'root': lambda w_idx,datum: self.afx(datum[0][w_idx]).root,\n",
    "                         'isdigit': lambda w_idx,datum: datum[0][w_idx].isdigit(),\n",
    "                         'pos': lambda w_idx,datum: datum[1][w_idx],\n",
    "                         'ner': lambda w_idx,datum: datum[2][w_idx],\n",
    "                         'dep_rel': lambda w_idx,datum: datum[3][w_idx],\n",
    "                         'dep_head': lambda w_idx,datum: datum[4][w_idx]} \n",
    "            # datum: (words, pos, ner, dep_rel, dep_head)\n",
    "        \n",
    "    def word_featurize(self, datum, i): \n",
    "        # datum: (sent, pos, ner, dep_rel, dep_head).\n",
    "        # i: index of the token processed. \n",
    "        features = []\n",
    "        for feat in self.feat_set.keys():\n",
    "            features.append(feat+'='+str(self.feat_set[feat](i,datum)))\n",
    "        if i > 0:\n",
    "            for feat in self.feat_set.keys():\n",
    "                features.append('-1'+feat+'='+str(self.feat_set[feat](i-1,datum)))\n",
    "                if i > 1:\n",
    "                    features.append('-2'+feat+'='+str(self.feat_set[feat](i-2,datum)))\n",
    "        else: features.append('BOS')\n",
    "        if i < len(datum[0])-1:\n",
    "            for feat in self.feat_set.keys():\n",
    "                features.append('+1'+feat+'='+str(str(self.feat_set[feat](i+1,datum))))\n",
    "                if i < len(datum[0])-2:\n",
    "                    features.append('+2'+feat+'='+str(str(self.feat_set[feat](i+2,datum))))\n",
    "        else: features.append('EOS')    \n",
    "        \n",
    "        return features\n",
    "        \n",
    "    def sent_featurize(self, datum):\n",
    "        # datum: (sent, pos, ner, dep_rel, dep_head).   \n",
    "        return [self.word_featurize(datum, i) for i in xrange(len(datum[0]))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featurizer = Featurize(prefix,suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['what', 'flights', 'leave', 'atlanta', 'at', 'about', 'DIGIT', 'in', 'the', 'afternoon', 'and', 'arrive', 'in', 'san', 'francisco'], [u'ADJ', u'NOUN', u'VERB', u'ADV', u'ADP', u'ADP', u'PROPN', u'ADP', u'DET', u'NOUN', u'CONJ', u'VERB', u'ADP', u'PROPN', u'NOUN'], ['none', 'none', 'none', 'none', 'none', 'none', u'ORG', 'none', 'none', u'TIME', 'none', 'none', 'none', 'none', 'none'], [u'det', u'nsubj', u'ROOT', u'advmod', u'prep', u'nmod', u'pobj', u'prep', u'det', u'pobj', u'cc', u'conj', u'prep', u'compound', u'pobj'], [u'flights', u'leave', u'leave', u'at', u'leave', u'DIGIT', u'at', u'DIGIT', u'afternoon', u'in', u'leave', u'leave', u'arrive', u'francisco', u'in'])\n"
     ]
    }
   ],
   "source": [
    "test_sent = X_train_augmented[0]\n",
    "print test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dep_rel=nsubj', 'ner=none', 'dep_head=leave', 'sfx=s', 'isdigit=False', 'pfx=no_pfx', 'root=flight', 'pos=NOUN', '-1dep_rel=det', '-1ner=none', '-1dep_head=flights', '-1sfx=no_sfx', '-1isdigit=False', '-1pfx=no_pfx', '-1root=what', '-1pos=ADJ', '+1dep_rel=ROOT', '+2dep_rel=advmod', '+1ner=none', '+2ner=none', '+1dep_head=leave', '+2dep_head=at', '+1sfx=no_sfx', '+2sfx=no_sfx', '+1isdigit=False', '+2isdigit=False', '+1pfx=no_pfx', '+2pfx=no_pfx', '+1root=leave', '+2root=atlanta', '+1pos=VERB', '+2pos=ADV']\n"
     ]
    }
   ],
   "source": [
    "print featurizer.word_featurize(test_sent,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dep_rel=det', 'ner=none', 'dep_head=flights', 'sfx=no_sfx', 'isdigit=False', 'pfx=no_pfx', 'root=what', 'pos=ADJ', 'BOS', '+1dep_rel=nsubj', '+2dep_rel=ROOT', '+1ner=none', '+2ner=none', '+1dep_head=leave', '+2dep_head=leave', '+1sfx=s', '+2sfx=no_sfx', '+1isdigit=False', '+2isdigit=False', '+1pfx=no_pfx', '+2pfx=no_pfx', '+1root=flight', '+2root=leave', '+1pos=NOUN', '+2pos=VERB']\n"
     ]
    }
   ],
   "source": [
    "print featurizer.sent_featurize(test_sent)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = [(x_augmented,y) for x_augmented,y in zip(X_train_augmented,Y_train)]\n",
    "test = [(x_augmented,y) for x_augmented,y in zip(X_test_augmented,Y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['what', 'flights', 'leave', 'atlanta', 'at', 'about', 'DIGIT', 'in', 'the', 'afternoon', 'and', 'arrive', 'in', 'san', 'francisco'], [u'ADJ', u'NOUN', u'VERB', u'ADV', u'ADP', u'ADP', u'PROPN', u'ADP', u'DET', u'NOUN', u'CONJ', u'VERB', u'ADP', u'PROPN', u'NOUN'], ['none', 'none', 'none', 'none', 'none', 'none', u'ORG', 'none', 'none', u'TIME', 'none', 'none', 'none', 'none', 'none'], [u'det', u'nsubj', u'ROOT', u'advmod', u'prep', u'nmod', u'pobj', u'prep', u'det', u'pobj', u'cc', u'conj', u'prep', u'compound', u'pobj'], [u'flights', u'leave', u'leave', u'at', u'leave', u'DIGIT', u'at', u'DIGIT', u'afternoon', u'in', u'leave', u'leave', u'arrive', u'francisco', u'in'])\n",
      "\n",
      "['O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-depart_time.time_relative', 'B-depart_time.time', 'O', 'O', 'B-depart_time.period_of_day', 'O', 'O', 'O', 'B-toloc.city_name', 'I-toloc.city_name']\n"
     ]
    }
   ],
   "source": [
    "print train[0][0]\n",
    "print \n",
    "print train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF (L-BFGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import os, cPickle, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CRF:\n",
    "    \n",
    "    def __init__(self, train, test, verbose=0, # train/test format: ((words,pos,ner,dep_rel,dep_head),labels).\n",
    "                 config={'c1': 1.0, # coef for L1.\n",
    "                         'c2': 1e-3, # coef for L2.\n",
    "                         'max_iterations': 100,\n",
    "                         'feature.possible_transitions':True}, # include unseen transitions.\n",
    "                 tagger_name='crf.crfsuite', # name of generated tagger.\n",
    "                 featurizer=Featurize(),\n",
    "                 save_featurized=False, # save featurized data.\n",
    "                 save_path=os.getcwd()):\n",
    "        print \"... featurizing data\"\n",
    "        self.featurizer = featurizer\n",
    "        self.X_train = [self.featurizer.sent_featurize(datum[0]) for datum in train]\n",
    "        self.Y_train = [datum[1] for datum in train]\n",
    "        self.X_test = [self.featurizer.sent_featurize(datum[0]) for datum in test]\n",
    "        self.Y_test = [datum[1] for datum in test]\n",
    "        if save_featurized:\n",
    "            cPickle.dump((self.X_train,self.Y_train,self.X_test,self.Y_test),\n",
    "                         open(save_path+time.ctime()+'data.p','wb')) # avoid overwriting data saved.\n",
    "        crf = pycrfsuite.Trainer(verbose=verbose)\n",
    "        print \"... loading data into CRF\"\n",
    "        for x,y in zip(self.X_train, self.Y_train):\n",
    "            crf.append(x,y)\n",
    "        crf.set_params(config)\n",
    "        print \"... training\"\n",
    "        crf.train(tagger_name)\n",
    "        self.tagger = pycrfsuite.Tagger()\n",
    "        self.tagger.open(tagger_name)\n",
    "    \n",
    "    def tag(self, sent): # takes a sentence as a string.\n",
    "        sent = sent.split()\n",
    "        sent = augment_info(sent) # (words,pos,ner,dep_rel,dep_head), which featurizer takes.\n",
    "        tags = self.tagger.tag(self.featurizer.sent_featurize(sent))\n",
    "        return zip(sent, tags)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        y_true = self.Y_test\n",
    "        y_pred = [self.tagger.tag(sent) for sent in self.X_test]\n",
    "        lb = LabelBinarizer()\n",
    "        y_true_in_tags = lb.fit_transform(list(chain.from_iterable(y_true))) # get a list of tags in 1-hot.\n",
    "        y_pred_in_tags = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        tagset = list(set(lb.classes_))\n",
    "        class_indices = {cls:idx for idx,cls in enumerate(lb.classes_)}\n",
    "        print classification_report(\n",
    "            y_true_in_tags,\n",
    "            y_pred_in_tags,\n",
    "            labels = [class_indices[cls] for cls in tagset],\n",
    "            target_names = tagset\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... featurizing data\n",
      "... loading data into CRF\n",
      "... training\n",
      "CPU times: user 5min 14s, sys: 1.38 s, total: 5min 15s\n",
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atis_crf = CRF(train, test, featurizer=Featurize(prefix,suffix), \n",
    "               save_featurized=True,save_path='/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/OJO/LUIS/DATA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "B-depart_date.today_relative       0.89      0.89      0.89         9\n",
      " B-arrive_date.date_relative       0.00      0.00      0.00         2\n",
      " B-depart_date.date_relative       0.77      1.00      0.87        17\n",
      "          I-restriction_code       1.00      0.33      0.50         3\n",
      "      B-depart_date.day_name       0.95      0.99      0.97       212\n",
      "      I-arrive_time.end_time       0.75      0.75      0.75         8\n",
      "      B-fromloc.airport_code       1.00      0.40      0.57         5\n",
      "             B-cost_relative       1.00      0.97      0.99        37\n",
      "                   B-connect       1.00      1.00      1.00         6\n",
      "             B-flight_number       0.85      1.00      0.92        11\n",
      " B-depart_time.time_relative       0.91      0.97      0.94        65\n",
      "           I-toloc.city_name       0.92      0.98      0.95       265\n",
      " B-arrive_time.period_of_day       0.57      0.67      0.62         6\n",
      " B-depart_time.period_of_day       0.96      0.90      0.93       130\n",
      " I-return_date.date_relative       0.00      0.00      0.00         3\n",
      "    I-depart_time.start_time       0.50      1.00      0.67         1\n",
      "               B-fare_amount       1.00      0.50      0.67         2\n",
      " I-depart_time.time_relative       0.00      0.00      0.00         1\n",
      "                 B-city_name       0.85      0.49      0.62        57\n",
      "    B-depart_date.day_number       0.90      1.00      0.95        55\n",
      "              I-airport_name       0.69      0.31      0.43        29\n",
      "          B-toloc.state_code       1.00      1.00      1.00        18\n",
      "    B-arrive_date.month_name       0.00      0.00      0.00         6\n",
      "      B-stoploc.airport_code       0.00      0.00      0.00         1\n",
      "              B-airport_code       0.50      0.44      0.47         9\n",
      "    B-arrive_time.start_time       1.00      0.12      0.22         8\n",
      "             B-period_of_day       0.00      0.00      0.00         4\n",
      "          B-arrive_time.time       0.93      0.76      0.84        34\n",
      "          B-toloc.state_name       0.86      0.43      0.57        28\n",
      "             B-booking_class       0.00      0.00      0.00         1\n",
      "      B-arrive_time.end_time       0.75      0.75      0.75         8\n",
      "                      B-meal       0.94      1.00      0.97        16\n",
      " B-arrive_time.time_relative       0.96      0.74      0.84        31\n",
      "                 I-city_name       0.77      0.33      0.47        30\n",
      "                  B-day_name       0.00      0.00      0.00         2\n",
      "                        B-or       0.50      1.00      0.67         3\n",
      "          I-arrive_time.time       0.93      0.77      0.84        35\n",
      "                   B-economy       1.00      1.00      1.00         6\n",
      "      B-fromloc.airport_name       0.32      0.58      0.41        12\n",
      "      B-return_date.day_name       0.00      0.00      0.00         2\n",
      "                           O       0.98      1.00      0.99      5535\n",
      "                B-class_type       0.96      1.00      0.98        24\n",
      "                 B-meal_code       0.00      0.00      0.00         1\n",
      "          B-depart_time.time       0.77      0.96      0.86        57\n",
      "    I-depart_date.day_number       1.00      1.00      1.00        15\n",
      "          B-restriction_code       1.00      0.25      0.40         4\n",
      "           B-fare_basis_code       0.82      0.82      0.82        17\n",
      "         I-stoploc.city_name       1.00      0.80      0.89        10\n",
      "                    B-flight       0.00      0.00      0.00         1\n",
      "      I-fromloc.airport_name       0.32      0.60      0.42        15\n",
      "               B-compartment       0.00      0.00      0.00         1\n",
      "              B-airline_code       0.97      0.94      0.96        34\n",
      "        B-fromloc.state_name       0.80      0.71      0.75        17\n",
      "               B-flight_stop       1.00      1.00      1.00        21\n",
      "                B-flight_mod       0.96      0.96      0.96        24\n",
      "    B-depart_time.start_time       0.25      0.67      0.36         3\n",
      " I-arrive_time.time_relative       0.00      0.00      0.00         4\n",
      "    B-arrive_date.day_number       0.00      0.00      0.00         6\n",
      "               I-flight_time       1.00      1.00      1.00         1\n",
      "      B-arrive_date.day_name       0.57      0.36      0.44        11\n",
      "        I-fromloc.state_name       0.00      0.00      0.00         1\n",
      "                       B-mod       0.00      0.00      0.00         2\n",
      "    B-depart_date.month_name       0.90      0.98      0.94        56\n",
      "               B-flight_days       1.00      0.90      0.95        10\n",
      "             I-cost_relative       1.00      0.67      0.80         3\n",
      "               B-flight_time       1.00      1.00      1.00         1\n",
      "         B-fromloc.city_name       0.96      0.97      0.96       704\n",
      "            B-transport_type       1.00      0.80      0.89        10\n",
      "        B-toloc.country_name       0.00      0.00      0.00         1\n",
      " B-return_date.date_relative       0.00      0.00      0.00         3\n",
      "                B-round_trip       0.99      0.97      0.98        73\n",
      "            I-transport_type       0.00      0.00      0.00         1\n",
      "         I-fromloc.city_name       0.92      0.94      0.93       177\n",
      "          B-depart_date.year       1.00      1.00      1.00         3\n",
      "                I-flight_mod       0.00      0.00      0.00         6\n",
      "           B-toloc.city_name       0.96      0.99      0.97       716\n",
      "    B-depart_time.period_mod       0.83      1.00      0.91         5\n",
      "    I-arrive_time.start_time       0.00      0.00      0.00         1\n",
      "                B-state_code       1.00      1.00      1.00         1\n",
      "              B-airport_name       0.60      0.29      0.39        21\n",
      "         B-stoploc.city_name       0.90      0.95      0.93        20\n",
      "        I-toloc.airport_name       0.50      0.33      0.40         3\n",
      "          B-meal_description       1.00      0.80      0.89        10\n",
      "                I-class_type       1.00      1.00      1.00        17\n",
      "        B-toloc.airport_code       0.00      0.00      0.00         4\n",
      " I-depart_time.period_of_day       1.00      1.00      1.00         1\n",
      "          I-toloc.state_name       0.00      0.00      0.00         1\n",
      "                 B-days_code       0.00      0.00      0.00         1\n",
      "        B-toloc.airport_name       0.50      0.33      0.40         3\n",
      "          I-depart_time.time       0.86      0.96      0.91        52\n",
      "                I-round_trip       1.00      1.00      1.00        71\n",
      "                I-state_name       0.00      0.00      0.00         1\n",
      "               I-fare_amount       1.00      0.50      0.67         2\n",
      "              B-airline_name       1.00      0.99      1.00       101\n",
      "             I-flight_number       0.00      0.00      0.00         1\n",
      "              I-airline_name       0.96      0.98      0.97        65\n",
      "                B-state_name       0.00      0.00      0.00         9\n",
      "      B-depart_time.end_time       0.50      0.33      0.40         3\n",
      "             B-aircraft_code       1.00      0.48      0.65        33\n",
      "        B-fromloc.state_code       1.00      1.00      1.00        23\n",
      "      I-depart_time.end_time       0.50      0.33      0.40         3\n",
      "\n",
      "                 avg / total       0.95      0.96      0.95      9198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "atis_crf.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = atis_crf.Y_test\n",
    "y_pred = [atis_crf.tagger.tag(sent) for sent in atis_crf.X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'O', 'O', 'O', 'O', 'B-stoploc.city_name', 'I-stoploc.city_name']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'O', 'O', 'O', 'O', 'B-stoploc.city_name', 'I-stoploc.city_name']\n"
     ]
    }
   ],
   "source": [
    "print y_true[0]\n",
    "print y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_merged = list(chain.from_iterable(y_true))\n",
    "y_pred_merged = list(chain.from_iterable(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy: %.2f\" % accuracy_score(y_true_merged,y_pred_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
